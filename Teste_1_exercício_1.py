# -*- coding: utf-8 -*-
"""Teste_1_Exercício_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gsvGo_SJ2ys2rIty3M0pzhjQo6OmUfaR
"""

!pip install scikit-learn imbalanced-learn pandas numpy

"""# **Bibliotecas**"""

# Bibliotecas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc

from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from sklearn.preprocessing import label_binarize

"""# **Funções**"""

# Função para calcular e exibir a matriz de confusão e AUC
def evaluate_and_plot(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)

    # Matriz de Confusão
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.show()

    # AUC
    y_test_bin = label_binarize(y_test, classes=np.unique(y_test))
    y_prob_bin = np.array(y_prob)

    plt.figure(figsize=(12, 10))
    for i in range(y_test_bin.shape[1]):
        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob_bin[:, i])
        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {auc(fpr, tpr):.2f})')

    plt.plot([0, 1], [0, 1], 'k--', label='Random')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('ROC Curve')
    plt.legend(loc='lower right')
    plt.show()

"""# **Exemplo**"""

# Simulação dos dados com 10 classes e textos abertos
np.random.seed(42)
text_samples = ['texto exemplo 1', 'texto exemplo 2', 'texto exemplo 3']
num_samples = 1000
text_repeats = np.repeat(text_samples, num_samples // len(text_samples) + 1)[:num_samples]

data = pd.DataFrame({
    'text': text_repeats,  # Ajustar a coluna de texto
    'feature1': np.random.randn(num_samples),
    'feature2': np.random.randn(num_samples),
    'feature3': np.random.randn(num_samples),
    'target': np.random.choice(range(10), num_samples)  # 10 classes
})

X = data[['text', 'feature1', 'feature2', 'feature3']]
y = data['target']

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Criar o pré-processador para as features numéricas e textuais
preprocessor = ColumnTransformer(
    transformers=[
        ('text', TfidfVectorizer(), 'text'),  # Vetorização do texto
        ('num', StandardScaler(), ['feature1', 'feature2', 'feature3'])  # Escalonamento dos dados numéricos
    ])

# Pipeline para RandomForest
pipeline_rf = ImbPipeline([
    ('preprocessor', preprocessor),  # Processamento de texto e numérico
    ('sampler', SMOTE()),  # Reamostragem para balancear as classes
    ('clf', RandomForestClassifier())  # Classificador
])

# Pipeline para SVM
pipeline_svc = ImbPipeline([
    ('preprocessor', preprocessor),  # Processamento de texto e numérico
    ('sampler', SMOTE()),  # Reamostragem para balancear as classes
    ('clf', SVC(probability=True))  # Classificador
])

# Pipeline para Regressão Logística
pipeline_lr = ImbPipeline([
    ('preprocessor', preprocessor),  # Processamento de texto e numérico
    ('sampler', SMOTE()),  # Reamostragem para balancear as classes
    ('clf', LogisticRegression(max_iter=10000))  # Classificador
])

# Definir parâmetros para GridSearch
param_grid_rf = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [None, 10, 20]
}

param_grid_svc = {
    'clf__C': [0.1, 1, 10],
    'clf__kernel': ['linear', 'rbf']
}

param_grid_lr = {
    'clf__C': [0.1, 1, 10],
    'clf__penalty': ['l2']
}

# GridSearchCV para RandomForest
grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, scoring='f1_weighted')
grid_rf.fit(X_train, y_train)
print("RandomForest - Best Parameters:", grid_rf.best_params_)
print("RandomForest - Classification Report:")
print(classification_report(y_test, grid_rf.predict(X_test)))

# GridSearchCV para SVM
grid_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring='f1_weighted')
grid_svc.fit(X_train, y_train)
print("SVM - Best Parameters:", grid_svc.best_params_)
print("SVM - Classification Report:")
print(classification_report(y_test, grid_svc.predict(X_test)))

# GridSearchCV para Regressão Logística
grid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, scoring='f1_weighted')
grid_lr.fit(X_train, y_train)
print("LogisticRegression - Best Parameters:", grid_lr.best_params_)
print("LogisticRegression - Classification Report:")
print(classification_report(y_test, grid_lr.predict(X_test)))

# Avaliar e plotar os modelos
print("\nEvaluating RandomForest:")
evaluate_and_plot(grid_rf.best_estimator_, X_test, y_test)

print("\nEvaluating SVM:")
evaluate_and_plot(grid_svc.best_estimator_, X_test, y_test)

print("\nEvaluating LogisticRegression:")
evaluate_and_plot(grid_lr.best_estimator_, X_test, y_test)